{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e5ea04-f15e-4322-afe2-e7956f690a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from loguru import logger\n",
    "\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf17de44-5acf-40ed-9863-a338c6b0dfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_song_urls() -> list:\n",
    "    \"\"\"\n",
    "    It returns a list of Zucchero's song lyrics urls.\n",
    "    \"\"\"\n",
    "    \n",
    "    url = \"https://www.zucchero.it/eng/lyrics/\"\n",
    "    page = urlopen(url)\n",
    "    html = page.read().decode(\"utf-8\")\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    song_urls = [item[\"href\"] for item in soup.find('div', {'class':'article-content'}).ul.find_all(href=True)]\n",
    "    \n",
    "    return song_urls\n",
    "\n",
    "@logger.catch\n",
    "def get_song_text(song_url: str) -> str:\n",
    "    \"\"\"\n",
    "    Given a song's url as input, it returns the text of the song scraped from the webpage.\n",
    "    \"\"\"\n",
    "    \n",
    "    page = urlopen(song_url)\n",
    "    html = page.read().decode(\"utf-8\")\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    condition1 = song_url in ['https://www.zucchero.it/eng/testi/alla-fine/',\n",
    "                              'https://www.zucchero.it/eng/testi/e-un-peccato-morir/','https://www.zucchero.it/eng/testi/god-bless-the-child/']\n",
    "    condition2 = song_url == 'https://www.zucchero.it/eng/testi/il-suono-della-domenica/'\n",
    "    condition3 = song_url in ['https://www.zucchero.it/eng/testi/diamante/',\n",
    "                             'https://www.zucchero.it/eng/testi/soldati-nella-mia-citta/','https://www.zucchero.it/eng/testi/spicinfrin-boy/', \n",
    "                              'https://www.zucchero.it/eng/oltre-le-rive/', 'https://www.zucchero.it/eng/alla-fine/', 'https://www.zucchero.it/eng/shake/']\n",
    "    try:\n",
    "        if condition1:\n",
    "            song_text = '. '.join([item.get_text().replace('\\n','. ') for item in soup.find('div', {'class':'article-content'}).find_all(\"p\")[1:] if '<em>' not in str(item)])\n",
    "        elif condition2:\n",
    "            song_text = '. '.join([item.get_text().replace('\\n','. ') for item in soup.find('div', {'class':'article-content'}).find_all(\"p\")[:-1] if '<em>' not in str(item)])\n",
    "        elif condition3:    \n",
    "            return\n",
    "        else:\n",
    "            song_text = '. '.join([item.get_text().replace('\\n','. ') for item in soup.find('div', {'class':'article-content'}).find_all(\"p\") if '<em>' not in str(item)])\n",
    "        return song_text\n",
    "    except:\n",
    "        return\n",
    "\n",
    "\n",
    "def build_dataset(songs: list, filename: str):\n",
    "    \"\"\"\n",
    "    Write a .txt file where each song includes the special tokens <BOS> at the beginning and <EOS> at the end.\n",
    "    \"\"\"\n",
    "    \n",
    "    f = open(f'{filename}.txt', 'w', encoding='utf-8')\n",
    "    data = ''\n",
    "    for song in songs:\n",
    "        song = str(song).strip()\n",
    "        bos_token = '<BOS>'\n",
    "        eos_token = '<EOS>'\n",
    "        data += bos_token + ' ' + song + ' ' + eos_token + '\\n'\n",
    "        \n",
    "    f.write(data)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebb2002-c502-4fa5-b18f-329efdea6d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "song_urls = get_song_urls()\n",
    "\n",
    "songs = []\n",
    "for url in tqdm(song_urls):\n",
    "    song_text = get_song_text(url)\n",
    "    if song_text in ['', None]:\n",
    "        continue\n",
    "    else:\n",
    "        songs.append(song_text)\n",
    "    \n",
    "x_train, x_test = train_test_split(songs, test_size=0.1, random_state=42)\n",
    "\n",
    "build_dataset(x_train, 'train')\n",
    "build_dataset(x_test, 'test')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0871ad75-348b-431b-bcd8-775b173d9d06",
   "metadata": {},
   "source": [
    "song_urls = get_song_urls()\n",
    "\n",
    "# Step 1: Init multiprocessing.Pool()\n",
    "pool = mp.Pool(mp.cpu_count())\n",
    "\n",
    "# Step 2: `pool.map` the `get_song_text()`\n",
    "song_lyrics = pool.map(get_song_text, [url for url in song_urls])\n",
    "\n",
    "# Step 3: Don't forget to close\n",
    "pool.close()    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
